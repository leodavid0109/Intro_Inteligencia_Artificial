{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL-cPPKRnbys"
      },
      "source": [
        "<center>\n",
        "\n",
        "# **Árboles y Clasificación Bayesiana: EJEMPLO 2:**\n",
        "Colab: https://colab.research.google.com/drive/1K9iPTCq1O2OVCIL0yMw34OXmOG7W7hPK?usp=sharing\n",
        "---\n",
        "Introducción a la Inteligencia Artificial, Código: 3010476\n",
        "\n",
        "Inteligencia Artificial, Código: 3007855\n",
        "\n",
        "---\n",
        "**Monitores:**\n",
        "\n",
        "Maria Alejandra Muñoz Alarcón\n",
        "\n",
        "---\n",
        "\n",
        "Denilson Andres Molina Truyot \n",
        "\n",
        "---\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "budy_nWyMtId"
      },
      "outputs": [],
      "source": [
        "# Cargar librerias\n",
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "import seaborn as sb\n",
        " \n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (16, 9)\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "# librerías Árboles de Decisión\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from IPython.display import Image as PImage\n",
        "from subprocess import check_call\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# librerías Gaussian Naive Bayes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import make_scorer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0PVLnmsp7M0"
      },
      "source": [
        "# CONTEXTO\n",
        "Las columnas que tenemos son:\n",
        "\n",
        "- *ingresos*: los ingresos mensuales de la familia\n",
        "- *gastos comunes*: pagos de luz, agua, gas, etc mensual\n",
        "- *pago coche*: si se está pagando cuota por uno o más coches, y los gastos en combustible, etc al mes.\n",
        "- *gastos_otros*: compra en supermercado y lo necesario para vivir al mes\n",
        "- *ahorros*: suma de ahorros dispuestos para usar en la compra de la casa.\n",
        "- *vivienda*: precio de la vivienda que quiere comprar esa familia\n",
        "- *estado civil*:\n",
        "  0. soltero\n",
        "  1. casados\n",
        "  2. divorciados\n",
        "- *hijos*: cantidad de hijos menores y que no trabajan.\n",
        "- *trabajo*:\n",
        "  0. sin empleo \n",
        "  1. autónomo (freelance)\n",
        "  2. empleado\n",
        "  3. empresario\n",
        "  4. pareja: autónomos\n",
        "  5. pareja: empleados\n",
        "  6. pareja: autónomo y asalariado\n",
        "  7. pareja:empresario y autónomo\n",
        "  8. pareja: empresarios los dos o empresario y empleado\n",
        "- comprar: (esta será nuestra columna de salida)\n",
        "  0. Alquilar \n",
        "  1. Comprar \n",
        "\n",
        "**Algunos supuestos para el problema formulado:**\n",
        "- Está pensado en Euros pero podría ser cualquier otra moneda\n",
        "- No tiene en cuenta ubicación geográfica (en la realidad esto afecta bastante el precio)\n",
        "- Se supone una hipoteca fija a 30 años con interés de mercado «bajo»."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvkEzl1IqfCi"
      },
      "outputs": [],
      "source": [
        "#Cargar datos.\n",
        "# Carga de datos o teniendo el csv en la carpeta nube del colab.\n",
        "#dataframe = pd.read_csv('comprar_alquilar.csv')\n",
        "#dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmIkXdyNqj68"
      },
      "outputs": [],
      "source": [
        "#Para abrir desde colab sin tenerlo en la nube.\n",
        "from google.colab import files\n",
        "import io\n",
        "uploaded = files.upload()\n",
        "dataframe = pd.read_csv(io.BytesIO(uploaded['comprar_alquilar.csv']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMvuJjE_owU_"
      },
      "source": [
        "## 1. Estadística descriptiva\n",
        "\n",
        "*Sug: Realizar todos los cambios que sean necesarios para los datos y luego realizar el análisis exploratorio de Variable Objetivo vs Atributos depurados.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMu7yGmPp13c"
      },
      "outputs": [],
      "source": [
        "print(dataframe.groupby('comprar').size())\n",
        "dataframe.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3yfQs9sq9UR"
      },
      "outputs": [],
      "source": [
        "dataframe.drop(['comprar'], axis=1).hist()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASk98geerG6o"
      },
      "source": [
        "### Cálculos financieros\n",
        "Procesando algunas de estas columnas podríamos agrupar los gastos. \n",
        "\n",
        "También crear una columna llamada financiar que será la resta del precio de la vivienda con los ahorros de la familia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCVMufxgrJaG"
      },
      "outputs": [],
      "source": [
        "dataframe['gastos']=(dataframe['gastos_comunes']+dataframe['gastos_otros']+dataframe['pago_coche'])\n",
        "dataframe['financiar']=dataframe['vivienda']-dataframe['ahorros']\n",
        "dataframe.drop(['gastos_comunes','gastos_otros','pago_coche'], axis=1).head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EfBilIkrREL"
      },
      "source": [
        "Ahora usando el `describe()` de pandas podemos ver los estadisticos de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIQMOEmnrMY7"
      },
      "outputs": [],
      "source": [
        "reduced = dataframe.drop(['gastos_comunes','gastos_otros','pago_coche','estado_civil','hijos','trabajo','comprar'], axis=1)\n",
        "reduced.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwCmrfQAwK3I"
      },
      "source": [
        "### Variable objetivo vs Datos involucrados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EvBS-BDwRw5"
      },
      "source": [
        "#### Usando `pairplot`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yH85QiF5wZN3"
      },
      "outputs": [],
      "source": [
        "#Visualizar relación si existe relación entre las variables que no son la variable objetivo\n",
        "sb.pairplot(dataframe.dropna(),\n",
        "            height=4, \n",
        "            vars=['comprar','ingresos'],\n",
        "            kind='scatter')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLMewvhGyT40"
      },
      "outputs": [],
      "source": [
        "#Visualizar relación si existe relación entre las variables que no son la variable objetivo\n",
        "sb.pairplot(dataframe.dropna(),\n",
        "            height=4, \n",
        "            vars=['comprar','gastos_comunes'],\n",
        "            kind='scatter')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Na8Aj_Yyj4f"
      },
      "outputs": [],
      "source": [
        "#Visualizar relación si existe relación entre las variables que no son la variable objetivo\n",
        "sb.pairplot(dataframe.dropna(),\n",
        "            height=4, \n",
        "            vars=['comprar','hijos'],\n",
        "            kind='scatter')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUz-sCaiy1G9"
      },
      "source": [
        "#### Otras formas. Útil para variables categóricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9-ddxWTyr2-"
      },
      "outputs": [],
      "source": [
        "g = sb.catplot(x='hijos', data=dataframe, hue='comprar', kind=\"count\")\n",
        "\n",
        "g.fig.suptitle(\"Comprar-Alquilar vs Hijos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f6sTtj3zXOe"
      },
      "outputs": [],
      "source": [
        "g = sb.catplot(x='estado_civil', data=dataframe, hue='comprar', kind=\"count\")\n",
        "\n",
        "g.fig.suptitle(\"Comprar-Alquilar vs estado_civil\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ukE6r-7hfam"
      },
      "source": [
        "## 2. Característica escogida para el nodo raíz. ¿Entropia o gini?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDOHMqKBhokx"
      },
      "outputs": [],
      "source": [
        "#Característica objetivo: Comprar\n",
        "\n",
        "#Mezclar datos\n",
        "dataframe=dataframe.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "#Todos los datos excepto la caracteristica comprar\n",
        "X = dataframe.drop(['comprar'], axis=1)\n",
        "\n",
        "#CARACTERÍSTICA OBJETIVO\n",
        "y = dataframe['comprar'] \n",
        "\n",
        "#¿Cuáles serían las características/atributos/variables que puede ser posibles candidatos al nodo raíz? Se debe analizar una hipótesis con el análisis exploratorio\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A14aubIdjRYA"
      },
      "source": [
        "### Entropía"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBEGObapjVOI"
      },
      "outputs": [],
      "source": [
        "cv = StratifiedKFold(n_splits=6, shuffle=True, random_state=1) \n",
        "accuracies = list()\n",
        "max_attributes = len(list(dataframe))\n",
        "depth_range = range(1, max_attributes + 1)\n",
        "\n",
        "# Testearemos la profundidad de 1 a cantidad de atributos +1\n",
        "for depth in depth_range:\n",
        "    fold_accuracy = []\n",
        "    tree_model = tree.DecisionTreeClassifier(criterion='entropy',\n",
        "                                             min_samples_split=20,\n",
        "                                             min_samples_leaf=5,\n",
        "                                             max_depth = depth,\n",
        "                                             class_weight='balanced') \n",
        "    for train_index, valid_index in cv.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[valid_index]\n",
        "        y_train, y_test = y[train_index], y[valid_index]\n",
        "\n",
        "        model = tree_model.fit(X_train, y_train)\n",
        "        valid_acc = model.score(X_test, y_test) # calculamos la precision con el segmento de validacion\n",
        "        fold_accuracy.append(valid_acc)\n",
        "\n",
        "    # almacenamos acc promedio para cada profundidad\n",
        "    avg = sum(fold_accuracy)/len(fold_accuracy)\n",
        "    accuracies.append(avg)\n",
        "    \n",
        "# Mostramos los resultados obtenidos\n",
        "df = pd.DataFrame({\"Max Depth\": depth_range, \"Average Accuracy\": accuracies})\n",
        "df = df[[\"Max Depth\", \"Average Accuracy\"]]\n",
        "print(df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odAoj8dyjbLk"
      },
      "source": [
        "### Gini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49ZiQywMjcTq"
      },
      "outputs": [],
      "source": [
        "cv = StratifiedKFold(n_splits=6, shuffle=True, random_state=1) \n",
        "accuracies = list()\n",
        "max_attributes = len(list(dataframe))\n",
        "depth_range = range(1, max_attributes + 1)\n",
        "\n",
        "# Testearemos la profundidad de 1 a cantidad de atributos +1\n",
        "for depth in depth_range:\n",
        "    fold_accuracy = []\n",
        "    tree_model = tree.DecisionTreeClassifier(criterion='gini',\n",
        "                                             min_samples_split=20,\n",
        "                                             min_samples_leaf=5,\n",
        "                                             max_depth = depth,\n",
        "                                             class_weight='balanced') \n",
        "    for train_index, valid_index in cv.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[valid_index]\n",
        "        y_train, y_test = y[train_index], y[valid_index]\n",
        "\n",
        "        model = tree_model.fit(X_train, y_train)\n",
        "        valid_acc = model.score(X_test, y_test) # calculamos la precision con el segmento de validacion\n",
        "        fold_accuracy.append(valid_acc)\n",
        "\n",
        "    # almacenamos acc promedio para cada profundidad\n",
        "    avg = sum(fold_accuracy)/len(fold_accuracy)\n",
        "    accuracies.append(avg)\n",
        "    \n",
        "# Mostramos los resultados obtenidos\n",
        "df = pd.DataFrame({\"Max Depth\": depth_range, \"Average Accuracy\": accuracies})\n",
        "df = df[[\"Max Depth\", \"Average Accuracy\"]]\n",
        "print(df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4vk0mRLjti6"
      },
      "source": [
        "## 3. Datos de entrenamiento y prueba.\n",
        "\n",
        "*Sug: Se crean árboles sin testear parámetros solo para tener una vista de los valores de exactitud variando el porcentaje de datos de entrenamiento y prueba. Se debe especificar que estos NO son los árboles definitivos.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAX2KhL-0wHV"
      },
      "source": [
        "### 10/90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DEmHWaCj5ex"
      },
      "outputs": [],
      "source": [
        "#Todos los datos excepto la caracteristica comprar\n",
        "X = dataframe.drop(['comprar'], axis=1)\n",
        "\n",
        "#Atributo OBJETIVO\n",
        "y = dataframe['comprar'] \n",
        "\n",
        "# Dividimos los datos para entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.1, #90% datos de entrenamiento, 10% prueba\n",
        "                                                    stratify = y,\n",
        "                                                    random_state = 1)\n",
        "# Datos de entrenaminto\n",
        "conteo = X_train.copy()\n",
        "conteo['label'] = y_train\n",
        "conteo.groupby('label').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP7ASMA907ud"
      },
      "outputs": [],
      "source": [
        "decision_tree = tree.DecisionTreeClassifier(criterion='gini',\n",
        "                                             min_samples_split=20,\n",
        "                                             min_samples_leaf=5,\n",
        "                                             max_depth = depth,\n",
        "                                             class_weight='balanced') \n",
        "\n",
        "# Ajustamos el modelo con los datos\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_train = decision_tree.predict(X_train)\n",
        "\n",
        "#Porcentaje de Exactitud con los datos de entrenamiento\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "print(\"Exactitud con datos de entrenamiento: {:.2f}\".format(acc_train))\n",
        "\n",
        "y_pred_test = decision_tree.predict(X_test)\n",
        "\n",
        "#Porcentaje de Exactitud con pruebas\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Exactitud con datos de pruebas: {:.2f}\".format(acc_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDZdNOEe04AF"
      },
      "source": [
        "### 20/80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7sx_NVd06Gu"
      },
      "outputs": [],
      "source": [
        "#Todos los datos excepto la caracteristica comprar\n",
        "X = dataframe.drop(['comprar'], axis=1)\n",
        "\n",
        "#Atributo OBJETIVO\n",
        "y = dataframe['comprar'] \n",
        "\n",
        "# Dividimos los datos para entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.2, #80% datos de entrenamiento, 20% prueba\n",
        "                                                    stratify = y,\n",
        "                                                    random_state = 1)\n",
        "# Datos de entrenaminto\n",
        "conteo = X_train.copy()\n",
        "conteo['label'] = y_train\n",
        "conteo.groupby('label').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf8ewlUWkTwY"
      },
      "outputs": [],
      "source": [
        "decision_tree = tree.DecisionTreeClassifier(criterion='gini',\n",
        "                                             min_samples_split=20,\n",
        "                                             min_samples_leaf=5,\n",
        "                                             max_depth = depth,\n",
        "                                             class_weight='balanced') \n",
        "\n",
        "# Ajustamos el modelo con los datos\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_train = decision_tree.predict(X_train)\n",
        "\n",
        "#Porcentaje de Exactitud con los datos de entrenamiento\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "print(\"Exactitud con datos de entrenamiento: {:.2f}\".format(acc_train))\n",
        "\n",
        "y_pred_test = decision_tree.predict(X_test)\n",
        "\n",
        "#Porcentaje de Exactitud con pruebas\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Exactitud con datos de pruebas: {:.2f}\".format(acc_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6E4kxid3Svg"
      },
      "source": [
        "### 30/80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5ps0lVM47XD"
      },
      "outputs": [],
      "source": [
        "#Todos los datos excepto la caracteristica comprar\n",
        "X = dataframe.drop(['comprar'], axis=1)\n",
        "\n",
        "#Atributo OBJETIVO\n",
        "y = dataframe['comprar'] \n",
        "\n",
        "# Dividimos los datos para entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.3, #70% datos de entrenamiento, 30% prueba\n",
        "                                                    stratify = y,\n",
        "                                                    random_state = 1)\n",
        "# Datos de entrenaminto\n",
        "conteo = X_train.copy()\n",
        "conteo['label'] = y_train\n",
        "conteo.groupby('label').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OUW5c0w47if"
      },
      "outputs": [],
      "source": [
        "decision_tree = tree.DecisionTreeClassifier(criterion='gini',\n",
        "                                             min_samples_split=20,\n",
        "                                             min_samples_leaf=5,\n",
        "                                             max_depth = depth,\n",
        "                                             class_weight='balanced') \n",
        "\n",
        "# Ajustamos el modelo con los datos\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_train = decision_tree.predict(X_train)\n",
        "\n",
        "#Porcentaje de Exactitud con los datos de entrenamiento\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "print(\"Exactitud con datos de entrenamiento: {:.2f}\".format(acc_train))\n",
        "\n",
        "y_pred_test = decision_tree.predict(X_test)\n",
        "\n",
        "#Porcentaje de Exactitud con pruebas\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Exactitud con datos de pruebas: {:.2f}\".format(acc_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdQ9Nbmk5d9Y"
      },
      "source": [
        "## 4. ¿Qué variables usar? ¿Gráficos de correlación?\n",
        "*Sug: Relacionar lo obtenido con los gráficos de correlación y SelectKBest, recuerden los costos computacionales de la técnica de árboles.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVnWJEgU5uly"
      },
      "source": [
        "###  Gráfico de Pearson: Correlación general de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXOEDnIo5y8S"
      },
      "outputs": [],
      "source": [
        "colormap = plt.cm.viridis\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.title('Pearson Correlation of Features')\n",
        "sb.heatmap(dataframe.astype(float).corr(),\n",
        "           vmax=1.0,\n",
        "           cmap=colormap,\n",
        "           annot=True,\n",
        "           linewidths=0.1,\n",
        "           linecolor='white',\n",
        "           square=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfmmAg666FCG"
      },
      "source": [
        "### Gráfico de Cramer V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVmAd30_6Jj1"
      },
      "outputs": [],
      "source": [
        "data_encoded = dataframe.copy()\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "def cramers_V(var1, var2):\n",
        "  crosstab = np.array(pd.crosstab(var1, var2, rownames=None, colnames=None))\n",
        "  stat = chi2_contingency(crosstab)[0]\n",
        "  obs = np.sum(crosstab)\n",
        "  mini = min(crosstab.shape) - 1\n",
        "  return (stat/(obs*mini))\n",
        "\n",
        "rows= []\n",
        "\n",
        "for var1 in data_encoded:\n",
        "  col = []\n",
        "  for var2 in data_encoded :\n",
        "    cramers =cramers_V(data_encoded[var1], data_encoded[var2])\n",
        "    col.append(round(cramers,2))\n",
        "  rows.append(col)\n",
        "  \n",
        "cramers_results = np.array(rows)\n",
        "df = pd.DataFrame(cramers_results, columns = data_encoded.columns, index =data_encoded.columns)\n",
        "with sb.axes_style(\"white\"):\n",
        "  ax = sb.heatmap(df,\n",
        "                  vmin=0.,\n",
        "                  vmax=1,\n",
        "                  cmap=colormap,\n",
        "                  annot=True,\n",
        "                  linewidths=0.1,\n",
        "                  square=True)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7rseW1b6vPp"
      },
      "source": [
        "### SelectKBest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDkPPLBc6xn6"
      },
      "outputs": [],
      "source": [
        "#Todos los datos excepto la caracteristica objetivo.\n",
        "X = dataframe.drop(['comprar'], axis=1)\n",
        "\n",
        "#CARACTERÍSTICA OBJETIVO\n",
        "y = dataframe['comprar']\n",
        "\n",
        "best=SelectKBest(k=len(list(dataframe))-1)    #len(list(dataframe))-1: Máximo numero de atributos\n",
        "                          #Para que el modelo no sea pesado, por el número de filas, deseo un número n=5, podrían ser más, hasta 12\n",
        "\n",
        "X_new = best.fit_transform(X, y)\n",
        "X_new.shape\n",
        "selected = best.get_support(indices=True)\n",
        "print(X.columns[selected])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDlCzjLP9Fhk"
      },
      "source": [
        "Sino me siento seguro, de cuáles variables coger, se pueden realizar pruebas sobre si mejoran o no la exactitud de los árboles usando las variables que me sugieren los gráficos de correlación y SelectKbest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5sfUJxz9WgB"
      },
      "source": [
        "#### n=5 atributos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EP04C5rS9qHO"
      },
      "outputs": [],
      "source": [
        "#Todos los datos excepto la caracteristica objetivo.\n",
        "X = dataframe.drop(['comprar'], axis=1)\n",
        "\n",
        "#CARACTERÍSTICA OBJETIVO\n",
        "y = dataframe['comprar']\n",
        "\n",
        "best=SelectKBest(k=5)    #len(list(dataframe))-1: Máximo numero de atributos\n",
        "                          #Para que el modelo no sea pesado, por el número de filas, deseo un número n=5, podrían ser más, hasta 12\n",
        "\n",
        "X_new = best.fit_transform(X, y)\n",
        "X_new.shape\n",
        "selected = best.get_support(indices=True)\n",
        "print(X.columns[selected])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMKld3wU9wND"
      },
      "outputs": [],
      "source": [
        "#Cuales atributos no están en la lista anterior\n",
        "dataframe.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdbeMg0n9RwI"
      },
      "outputs": [],
      "source": [
        "#Todos los datos excepto la caracteristica comprar\n",
        "X = dataframe.drop(['comprar','gastos_comunes','pago_coche','gastos_otros','vivienda','estado_civil'], axis=1)\n",
        "\n",
        "#Atributo OBJETIVO\n",
        "y = dataframe['comprar'] \n",
        "\n",
        "# Dividimos los datos para entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.1, #90% datos de entrenamiento, 10% prueba\n",
        "                                                    stratify = y,\n",
        "                                                    random_state = 1)\n",
        "# Datos de entrenaminto\n",
        "conteo = X_train.copy()\n",
        "conteo['label'] = y_train\n",
        "conteo.groupby('label').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mqqj39Jh-KCI"
      },
      "outputs": [],
      "source": [
        "decision_tree = tree.DecisionTreeClassifier(criterion='gini',\n",
        "                                             min_samples_split=20,\n",
        "                                             min_samples_leaf=5,\n",
        "                                             max_depth = depth,\n",
        "                                             class_weight='balanced') \n",
        "\n",
        "# Ajustamos el modelo con los datos\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_train = decision_tree.predict(X_train)\n",
        "\n",
        "#Porcentaje de Exactitud con los datos de entrenamiento\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "print(\"Exactitud con datos de entrenamiento: {:.2f}\".format(acc_train))\n",
        "\n",
        "y_pred_test = decision_tree.predict(X_test)\n",
        "\n",
        "#Porcentaje de Exactitud con pruebas\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Exactitud con datos de pruebas: {:.2f}\".format(acc_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej6Co1sl-XR5"
      },
      "source": [
        "#### n=6 atributos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q-K4CJz-Y-H"
      },
      "outputs": [],
      "source": [
        "#Todos los datos excepto la caracteristica objetivo.\n",
        "X = dataframe.drop(['comprar'], axis=1)\n",
        "\n",
        "#CARACTERÍSTICA OBJETIVO\n",
        "y = dataframe['comprar']\n",
        "\n",
        "best=SelectKBest(k=6)    #len(list(dataframe))-1: Máximo numero de atributos\n",
        "                          #Para que el modelo no sea pesado, por el número de filas, deseo un número n=6, podrían ser más, hasta 12\n",
        "\n",
        "X_new = best.fit_transform(X, y)\n",
        "X_new.shape\n",
        "selected = best.get_support(indices=True)\n",
        "print(X.columns[selected])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wbo7MxTn-fwG"
      },
      "outputs": [],
      "source": [
        "#Cuales atributos no están en la lista anterior\n",
        "dataframe.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZkLV4se-j4N"
      },
      "outputs": [],
      "source": [
        "#Todos los datos excepto la caracteristica comprar\n",
        "X = dataframe.drop(['comprar','pago_coche','gastos_otros','vivienda','estado_civil'], axis=1)\n",
        "\n",
        "#Atributo OBJETIVO\n",
        "y = dataframe['comprar'] \n",
        "\n",
        "# Dividimos los datos para entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.1, #90% datos de entrenamiento, 10% prueba\n",
        "                                                    stratify = y,\n",
        "                                                    random_state = 1)\n",
        "# Datos de entrenaminto\n",
        "conteo = X_train.copy()\n",
        "conteo['label'] = y_train\n",
        "conteo.groupby('label').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUKw8hbb-wxS"
      },
      "outputs": [],
      "source": [
        "decision_tree = tree.DecisionTreeClassifier(criterion='gini',\n",
        "                                             min_samples_split=20,\n",
        "                                             min_samples_leaf=5,\n",
        "                                             max_depth = depth,\n",
        "                                             class_weight='balanced') \n",
        "\n",
        "# Ajustamos el modelo con los datos\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_train = decision_tree.predict(X_train)\n",
        "\n",
        "#Porcentaje de Exactitud con los datos de entrenamiento\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "print(\"Exactitud con datos de entrenamiento: {:.2f}\".format(acc_train))\n",
        "\n",
        "y_pred_test = decision_tree.predict(X_test)\n",
        "\n",
        "#Porcentaje de Exactitud con pruebas\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Exactitud con datos de pruebas: {:.2f}\".format(acc_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psfh85VT-4Vy"
      },
      "source": [
        "#### n=7 atributos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K833EaU-6_F"
      },
      "outputs": [],
      "source": [
        "#Todos los datos excepto la caracteristica objetivo.\n",
        "X = dataframe.drop(['comprar'], axis=1)\n",
        "\n",
        "#CARACTERÍSTICA OBJETIVO\n",
        "y = dataframe['comprar']\n",
        "\n",
        "best=SelectKBest(k=7)    #len(list(dataframe))-1: Máximo numero de atributos\n",
        "                          #Para que el modelo no sea pesado, por el número de filas, deseo un número n=5, podrían ser más, hasta 12\n",
        "\n",
        "X_new = best.fit_transform(X, y)\n",
        "X_new.shape\n",
        "selected = best.get_support(indices=True)\n",
        "print(X.columns[selected])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIIZALuq_G6v"
      },
      "outputs": [],
      "source": [
        "#Cuales atributos no están en la lista anterior\n",
        "dataframe.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbDrIrtW_Kby"
      },
      "outputs": [],
      "source": [
        "#Todos los datos excepto la caracteristica comprar\n",
        "X = dataframe.drop(['comprar','gastos_otros','vivienda','estado_civil'], axis=1)\n",
        "\n",
        "#Atributo OBJETIVO\n",
        "y = dataframe['comprar'] \n",
        "\n",
        "# Dividimos los datos para entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.1, #90% datos de entrenamiento, 10% prueba\n",
        "                                                    stratify = y,\n",
        "                                                    random_state = 1)\n",
        "# Datos de entrenaminto\n",
        "conteo = X_train.copy()\n",
        "conteo['label'] = y_train\n",
        "conteo.groupby('label').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "284gfhn-_Ods"
      },
      "outputs": [],
      "source": [
        "decision_tree = tree.DecisionTreeClassifier(criterion='gini',\n",
        "                                             min_samples_split=20,\n",
        "                                             min_samples_leaf=5,\n",
        "                                             max_depth = depth,\n",
        "                                             class_weight='balanced') \n",
        "\n",
        "# Ajustamos el modelo con los datos\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_train = decision_tree.predict(X_train)\n",
        "\n",
        "#Porcentaje de Exactitud con los datos de entrenamiento\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "print(\"Exactitud con datos de entrenamiento: {:.2f}\".format(acc_train))\n",
        "\n",
        "y_pred_test = decision_tree.predict(X_test)\n",
        "\n",
        "#Porcentaje de Exactitud con pruebas\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Exactitud con datos de pruebas: {:.2f}\".format(acc_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i10JsyC5_rbK"
      },
      "source": [
        "## 5. Diferentes alturas del árbol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKnib6fU_x2V"
      },
      "outputs": [],
      "source": [
        "#Luego del análisis anterior, me quedo con el conjunto de variables que deseo\n",
        "df_def = dataframe.drop(['pago_coche','gastos_otros','vivienda','estado_civil'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mT8EVLVAQK4"
      },
      "outputs": [],
      "source": [
        "X = df_def.drop(['comprar'], axis=1)\n",
        "y = df_def['comprar']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzWIOXM8AI06"
      },
      "outputs": [],
      "source": [
        "#Para usar este método X y 'y' deben ser listas np\n",
        "X=np.array(X)\n",
        "y=np.array(y)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=6, shuffle=True, random_state=1) \n",
        "accuracies = list()\n",
        "max_attributes = len(list(dataframe))\n",
        "depth_range = range(1, max_attributes + 1)\n",
        "\n",
        "# Testearemos la profundidad de 1 a cantidad de atributos +1\n",
        "for depth in depth_range:\n",
        "    fold_accuracy = []\n",
        "    tree_model = tree.DecisionTreeClassifier(criterion='gini',\n",
        "                                             min_samples_split=20,\n",
        "                                             min_samples_leaf=5,\n",
        "                                             max_depth = depth,\n",
        "                                             class_weight='balanced') \n",
        "    for train_index, valid_index in cv.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[valid_index]\n",
        "        y_train, y_test = y[train_index], y[valid_index]\n",
        "\n",
        "        model = tree_model.fit(X_train, y_train)\n",
        "        valid_acc = model.score(X_test, y_test) # calculamos la precision con el segmento de validacion\n",
        "        fold_accuracy.append(valid_acc)\n",
        "\n",
        "    # almacenamos acc promedio para cada profundidad\n",
        "    avg = sum(fold_accuracy)/len(fold_accuracy)\n",
        "    accuracies.append(avg)\n",
        "    \n",
        "# Mostramos los resultados obtenidos\n",
        "df = pd.DataFrame({\"Max Depth\": depth_range, \"Average Accuracy\": accuracies})\n",
        "df = df[[\"Max Depth\", \"Average Accuracy\"]]\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "#¿Dónde se alcanza el mejor valor de exactitud?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPh67b59BKyq"
      },
      "source": [
        "## 6. Mínimo de muestras por nodo, mínimo de muestra por hoja. ¿Fue necesario balancear las clases para los datos de entrenamiento?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4BGj4-GBl5X"
      },
      "outputs": [],
      "source": [
        "X = df_def.drop(['comprar'], axis=1)\n",
        "y = df_def['comprar']\n",
        "\n",
        "# Dividimos los datos para entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.1, #90% datos de entrenamiento, 10% prueba\n",
        "                                                    stratify = y,\n",
        "                                                    random_state = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fT_q3gntBZgd"
      },
      "outputs": [],
      "source": [
        "conteo = X_train.copy()\n",
        "conteo['label'] = y_train\n",
        "conteo.groupby('label').size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiAIvUdQCBSI"
      },
      "source": [
        "Se va a instanciar el árbol con una altura igual a 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQfnbKFDCF6u"
      },
      "outputs": [],
      "source": [
        "# Instanciar Arbol de decision con profundidad = 5\n",
        "decision_tree = tree.DecisionTreeClassifier(criterion='gini',\n",
        "                                            #Restricciones que evitan Overfitting.\n",
        "                                            min_samples_split=5, #5. Qué pasa si varió el número de muestras mínimo por nodo.\n",
        "                                            min_samples_leaf=2,   #5. Qué pasa si vario el número de muestras mínimo por hoja (Las hojas es el nodo final del).\n",
        "                                            max_depth = 8,    #4. Testear qué pasa si aumento o disminuyo la altura del arbol.\n",
        "                                                              #Tener en cuenta que la altura va desde 1 hasta el número de atributos (Variables).\n",
        "                                            class_weight='balanced')  #Balanceo automático\n",
        "                                            #class_weight={0:1, 1:w})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR6xLIGACLib"
      },
      "outputs": [],
      "source": [
        "# Ajustamos el modelo con los datos\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "#Cada cambio que se haga requiere analizar o tener en cuenta su nivel de exactitud.\n",
        "\n",
        "#Exactitud\n",
        "\n",
        "#Datos de entrenamiento\n",
        "y_pred_train = decision_tree.predict(X_train)\n",
        "\n",
        "#Porcentaje de exactitud con los datos de entrenamiento\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "print(\"Exactitud con datos de entrenamiento: {:.2f}\".format(acc_train))\n",
        "\n",
        "#Datos de prueba\n",
        "y_pred_test = decision_tree.predict(X_test)\n",
        "\n",
        "#Porcentaje de exactitud con pruebas\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Exactitud con datos de pruebas: {:.2f}\".format(acc_test))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhWHrO_vCPgR"
      },
      "outputs": [],
      "source": [
        "# exportar el modelo a archivo .dot y graficar\n",
        "with open(r\"tree1.dot\", 'w') as f:\n",
        "     f = tree.export_graphviz(decision_tree,\n",
        "                              out_file=f,\n",
        "                              max_depth = 8,\n",
        "                              impurity = True,\n",
        "                              feature_names = list(df_def.drop(['comprar'], axis=1)),\n",
        "                              class_names = ['Alquilar', 'Comprar'],\n",
        "                              rounded = True,\n",
        "                              filled= True )\n",
        "        \n",
        "# Convertir el archivo .dot a png para poder visualizarlo\n",
        "check_call(['dot','-Tpng',r'tree1.dot','-o',r'tree1.png'])\n",
        "PImage(\"tree1.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A7AMGhaDKFL"
      },
      "source": [
        "## 7. Matriz de confunsión.\n",
        "* tp (True positive): Valor que es verdad y que el modelo predijo correctamente.\n",
        "* fn (False negative): Valor que es verdad y el modelo predijo incorrectamente.\n",
        "* fp (False positive): Valor que no es verdad y que el modelo predijo incorrectamente.\n",
        "* tn (True negative): Valor que no es verdad y que el modelo predijo correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCXgTTfcDYgL"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_K5S1WrHDLm_"
      },
      "outputs": [],
      "source": [
        "disp = plot_confusion_matrix(decision_tree, X_train, y_train,\n",
        "                                 display_labels=['Alquilar','Comprar'],\n",
        "                                 cmap=plt.cm.Blues,\n",
        "                                 normalize=None)\n",
        "disp.ax_.set_title('Matriz de confusión del Árbol en Entrenamiento', y=1.02, size=18)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqgovYABFdOs"
      },
      "source": [
        "### Prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrdD9fDxFfVK"
      },
      "outputs": [],
      "source": [
        "disp = plot_confusion_matrix(decision_tree, X_test, y_test,\n",
        "                                 display_labels=['Alquilar','Comprar'],\n",
        "                                 cmap=plt.cm.Blues,\n",
        "                                 normalize=None)\n",
        "disp.ax_.set_title('Matriz de confusión del Árbol en Prueba', y=1.02, size=18)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TOhcXZDDiod"
      },
      "source": [
        "## 8. Métrica de exactitud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m06eN5bOF_Gr"
      },
      "source": [
        "### Entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkQPu5xzF7Oo"
      },
      "outputs": [],
      "source": [
        "y_pred_train = decision_tree.predict(X_train)\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "print(\"Train set accuracy: {:.2f}\".format(acc_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pmKSfQVGAs9"
      },
      "source": [
        "### Prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBLfUCxiGCvY"
      },
      "outputs": [],
      "source": [
        "y_pred_test = decision_tree.predict(X_test)\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Test set accuracy: {:.2f}\".format(acc_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlMk-iH3GMk-"
      },
      "source": [
        "## 9. F1-Score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6eJ4lSdGSM1"
      },
      "source": [
        "### Entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H71PpxlFGQn3"
      },
      "outputs": [],
      "source": [
        "decoded_y_test = y_train\n",
        "decoded_predictions = decision_tree.predict(X_train)\n",
        "print(f'Reporte de clasificación:')\n",
        "print(classification_report(decoded_y_test,\n",
        "                            decoded_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqSOqw-RGYym"
      },
      "source": [
        "### Prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sMkUbSsGbut"
      },
      "outputs": [],
      "source": [
        "decoded_y_test = y_test\n",
        "decoded_predictions = decision_tree.predict(X_test)\n",
        "print(f'Reporte de clasificación:')\n",
        "print(classification_report(decoded_y_test,\n",
        "                            decoded_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJfZMF_ZGoon"
      },
      "source": [
        "## 10. Clasificación bayesiana."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vyiYgX-Gqn9"
      },
      "outputs": [],
      "source": [
        "#Ajustando el modelo\n",
        "# Instantiate the classifier\n",
        "gnb = GaussianNB()\n",
        "# Train classifier\n",
        "gnb.fit(\n",
        "    X_train,\n",
        "    y_train\n",
        ")\n",
        "y_pred = gnb.predict(X_test)\n",
        " \n",
        "print('Accuracy in training set: {:.2f}'\n",
        "     .format(gnb.score(X_train, y_train)))\n",
        "print('Accuracy in test set: {:.2f}'\n",
        "     .format(gnb.score(X_test, y_test)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PlrFHMDHKsM"
      },
      "source": [
        "### Matriz de confusión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC76FS1xHMTk"
      },
      "source": [
        "#### Entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Od55RH89HQRH"
      },
      "outputs": [],
      "source": [
        "disp = plot_confusion_matrix(gnb, X_train, y_train,\n",
        "                                 display_labels=['Alquilar','Comprar'],\n",
        "                                 cmap=plt.cm.Blues,\n",
        "                                 normalize=None)\n",
        "disp.ax_.set_title('Matriz de confusión del clasificador bayesiano en Entrenamiento', y=1.02, size=18)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-5fDdTeHRxj"
      },
      "source": [
        "#### Prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2ifaradHUII"
      },
      "outputs": [],
      "source": [
        "disp = plot_confusion_matrix(gnb, X_test, y_test,\n",
        "                                 display_labels=['Alquilar','Comprar'],\n",
        "                                 cmap=plt.cm.Blues,\n",
        "                                 normalize=None)\n",
        "disp.ax_.set_title('Matriz de confusión del clasificador bayesiano en Prueba', y=1.02, size=18)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PesYLKnYH6Rj"
      },
      "source": [
        "### F1-Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjCbNdg9H_kc"
      },
      "source": [
        "#### Entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzDIxAttIBBi"
      },
      "outputs": [],
      "source": [
        "decoded_y_test = y_train\n",
        "decoded_predictions = gnb.predict(X_train)\n",
        "print(f'Reporte de clasificación:')\n",
        "print(classification_report(decoded_y_test,\n",
        "                            decoded_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87_kz5UKIHjM"
      },
      "source": [
        "#### Prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayYuskgGIKSM"
      },
      "outputs": [],
      "source": [
        "decoded_y_test = y_test\n",
        "decoded_predictions = gnb.predict(X_test)\n",
        "print(f'Reporte de clasificación:')\n",
        "print(classification_report(decoded_y_test,\n",
        "                            decoded_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebEog15cIUJj"
      },
      "source": [
        "## 11. Análisis de resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KVqicJyKyEH"
      },
      "source": [
        "### Clasificador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCEf4fSUIpMX"
      },
      "outputs": [],
      "source": [
        "#¿Qué variables/atributos tengo?\n",
        "df_def.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oU3ZaKxIYfq"
      },
      "outputs": [],
      "source": [
        "#Predicción con ambos modelos\n",
        "data = {'ingresos':[2000,6000,2000],\n",
        "        'gastos_comunes':[1360,920,1200],\n",
        "        'ahorros':[5000,34000,10000],\n",
        "        'hijos':[0,2,1],\n",
        "        'trabajo':[5,5,8],\n",
        "        'gastos':[2500,2000,1000],\n",
        "        'financiar':[200000,320000,150000]}\n",
        "prueba = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljQuUMCQJIK4"
      },
      "outputs": [],
      "source": [
        "print(gnb.predict(prueba))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h2Zg6nIJy5R"
      },
      "outputs": [],
      "source": [
        "#¿Qué tan seguro es la predicción del clasificador?\n",
        "x_test=pd.DataFrame(columns=('comprar','ingresos','gastos_comunes','ahorros','hijos','trabajo','gastos','financiar'))\n",
        "x_test.loc[0]=(1000,2000,1360,5000,0,5,2500,200000)    #El primer dato es de comprar y no importa, ya que ese valor es el que se va a predecir\n",
        "y_pred = gnb.predict(x_test.drop(['comprar'], axis = 1)) #Saca 'comprar':  Característica obj\n",
        "print(\"Prediccion: \" + str(y_pred))\n",
        "y_proba = gnb.predict_proba(x_test.drop(['comprar'], axis = 1))\n",
        "print(\"Probabilidad de Acierto: \" + str(np.round(y_proba[0][y_pred]* 100, 2)) + \"%\")     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YE9xbuO7KYgh"
      },
      "outputs": [],
      "source": [
        "x_test.loc[0]=(1000,6000,920,34000,2,5,2000,320000)    #El primer dato es de comprar y no importa, ya que ese valor es el que se va a predecir\n",
        "y_pred = gnb.predict(x_test.drop(['comprar'], axis = 1)) #Saca 'comprar':  Característica obj\n",
        "print(\"Prediccion: \" + str(y_pred))\n",
        "y_proba = gnb.predict_proba(x_test.drop(['comprar'], axis = 1))\n",
        "print(\"Probabilidad de Acierto: \" + str(np.round(y_proba[0][y_pred]* 100, 2)) + \"%\")     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpboUVFYK0P_"
      },
      "source": [
        "### Árbol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJPBzpEcK1ZH"
      },
      "outputs": [],
      "source": [
        "x_test.loc[0]=(1000,2000,1360,5000,0,5,2500,200000)    #El primer dato es de comprar y no importa, ya que ese valor es el que se va a predecir\n",
        "y_pred = decision_tree.predict(x_test.drop(['comprar'], axis = 1)) #Saca 'comprar':  Característica obj\n",
        "print(\"Prediccion: \" + str(y_pred))\n",
        "y_proba = decision_tree.predict_proba(x_test.drop(['comprar'], axis = 1))\n",
        "print(\"Probabilidad de Acierto: \" + str(np.round(y_proba[0][y_pred]* 100, 2)) + \"%\")    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSgOdw33LDCA"
      },
      "outputs": [],
      "source": [
        "x_test.loc[0]=(1000,6000,920,34000,2,5,2000,320000)    #El primer dato es de comprar y no importa, ya que ese valor es el que se va a predecir\n",
        "y_pred = decision_tree.predict(x_test.drop(['comprar'], axis = 1)) #Saca 'comprar':  Característica obj\n",
        "print(\"Prediccion: \" + str(y_pred))\n",
        "y_proba = decision_tree.predict_proba(x_test.drop(['comprar'], axis = 1))\n",
        "print(\"Probabilidad de Acierto: \" + str(np.round(y_proba[0][y_pred]* 100, 2)) + \"%\")     "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "mPh67b59BKyq",
        "87_kz5UKIHjM",
        "ebEog15cIUJj",
        "5KVqicJyKyEH",
        "gpboUVFYK0P_"
      ],
      "name": "Taller6.2_DT_GNB.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
